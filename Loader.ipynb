{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "import sys\n",
    "#import sys.path\n",
    "sys.path.append(r'C:\\Users\\pasan\\Documents\\Motivation\\cocoapi-master\\PythonAPI')\n",
    "\n",
    "import pycocotools\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='..'\n",
    "dataType='val2017'\n",
    "annFile='C:/Users/pasan/Documents/Motivation/cocoapi-master/PythonAPI/annotations/instances_train2017.json'.format(dataDir,dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "C:/Users/pasan/Documents/Motivation/cocoapi-master/PythonAPI/annotations/instances_train2017.json\n",
      "Done (t=28.56s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# initialize COCO api for instance annotations\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "C:/Users/pasan/Documents/Motivation/cocoapi-master/PythonAPI/annotations/captions_train2017.json\n",
      "Done (t=2.85s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# initialize COCO api for caption annotations\n",
    "annFile = 'C:/Users/pasan/Documents/Motivation/cocoapi-master/PythonAPI/annotations/captions_train2017.json'.format(dataDir,dataType)\n",
    "coco_caps=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images, category : people -  64115\n",
      "\n",
      "\n",
      "Image Id:  262145 \n",
      "\n",
      "image tensor shape:  torch.Size([480, 640, 3])\n",
      "Annotation IDs: \n",
      "[694, 1054, 1456]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "People shopping in an open market for vegetables.\n",
      "An open market full of people and piles of vegetables.\n",
      "People are shopping at an open air produce market.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  262146 \n",
      "\n",
      "image tensor shape:  torch.Size([640, 425, 3])\n",
      "Annotation IDs: \n",
      "[634780, 637393, 640348]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "a person skiing down a steep hill \n",
      "A person skiing down a steep snowy hill.\n",
      "A person on snow skis going down a steep slope.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  524291 \n",
      "\n",
      "image tensor shape:  torch.Size([480, 640, 3])\n",
      "Annotation IDs: \n",
      "[714950, 716729, 718211]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "The black and white dog stands near a person holding a Frisbee. \n",
      "A dog is looking at a blue Frisbee.\n",
      "A dog watches a person who is holding a Frisbee.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  262148 \n",
      "\n",
      "image tensor shape:  torch.Size([333, 500, 3])\n",
      "Annotation IDs: \n",
      "[284571, 286347, 286899]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "The skateboarder is putting on a show using the picnic table as his stage.\n",
      "A skateboarder pulling tricks on top of a picnic table.\n",
      "A man riding on a skateboard on top of a table.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  393223 \n",
      "\n",
      "image tensor shape:  torch.Size([612, 612, 3])\n",
      "Annotation IDs: \n",
      "[748954, 749497, 750919]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A woman wearing a necklace is brushing her teeth.\n",
      "A man that is holding a toothbrush in his mouth.\n",
      "A closeup of a girl brushing her teeth\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  393224 \n",
      "\n",
      "image tensor shape:  torch.Size([480, 640, 3])\n",
      "Annotation IDs: \n",
      "[159820, 165088, 167779]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man stands with a frown on his face.\n",
      "A old man in coat and tie walking down a busy street.\n",
      "An old man in a business suit has a thoughtful face. \n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  524297 \n",
      "\n",
      "image tensor shape:  torch.Size([640, 427, 3])\n",
      "Annotation IDs: \n",
      "[357165, 361053, 364968]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A vintage photo of two men and a lama. \n",
      "A black and white image of two guys and a bear. \n",
      "Two people standing in the middle of an empty street with a bear on a rope.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  393227 \n",
      "\n",
      "image tensor shape:  torch.Size([640, 480, 3])\n",
      "Annotation IDs: \n",
      "[721402, 730579, 732109]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A young man riding a skateboard on top of a park.\n",
      "A skateboarder in jeans is crouched down low.\n",
      "a man is doing a trick on a skateboard\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  131084 \n",
      "\n",
      "image tensor shape:  torch.Size([480, 640, 3])\n",
      "Annotation IDs: \n",
      "[134145, 138576, 138690]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man on a motorcycle riding a dirt track.\n",
      "A person wearing a helmet is riding a motorcycle\n",
      "A dirt bike rider rides on a dirt path\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  393230 \n",
      "\n",
      "image tensor shape:  torch.Size([331, 500, 3])\n",
      "Annotation IDs: \n",
      "[205119, 209493, 210612]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man riding skis down a snow covered slope.\n",
      "Someone cross country skiing in their back yard\n",
      "A person is skiing over a snowy hill.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  262161 \n",
      "\n",
      "image tensor shape:  torch.Size([640, 640, 3])\n",
      "Annotation IDs: \n",
      "[663851, 664541, 665543]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "Large motorcycle sitting on a grassy area in a line.\n",
      "Older motorcycle displayed on grass along with several old cars.\n",
      "A motorcycle that is parked in a field.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  131089 \n",
      "\n",
      "image tensor shape:  torch.Size([640, 640, 3])\n",
      "Annotation IDs: \n",
      "[325240, 325846, 326521]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A young child in the yard holding up a bat.\n",
      "A boy raring back with a baseball bat in a yard.\n",
      "A little boy has a baseball bat in a yard.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  524311 \n",
      "\n",
      "image tensor shape:  torch.Size([427, 640, 3])\n",
      "Annotation IDs: \n",
      "[44070, 45426, 46785]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man holding a Wii remote and laughing.\n",
      "a man in a blue walled room playing with a wii mote\n",
      "A man holding a white Wii remote laughs\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  393241 \n",
      "\n",
      "image tensor shape:  torch.Size([445, 640, 3])\n",
      "Annotation IDs: \n",
      "[223260, 235668, 236379]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A couple of people playing a game of frisbee.\n",
      "Two people are playing Frisbee on the field.\n",
      "Two people playing frisbee against each other on a field.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  524314 \n",
      "\n",
      "image tensor shape:  torch.Size([480, 640, 3])\n",
      "Annotation IDs: \n",
      "[416206, 417373, 417592]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man in red jacket sitting with stuffed animals on street.\n",
      "a person sitting on the ground with stuffed animals \n",
      "The man on the sidewalk is sitting next to stuffed animals. \n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  393243 \n",
      "\n",
      "image tensor shape:  torch.Size([346, 640, 3])\n",
      "Annotation IDs: \n",
      "[211126, 212533, 220261]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A small child is eating a donut fed by another hand.\n",
      "A blonde boy looking at his donut hole.\n",
      "A boy is looking at a small doughnut with powdered sugar on his face.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  262171 \n",
      "\n",
      "image tensor shape:  torch.Size([428, 640, 3])\n",
      "Annotation IDs: \n",
      "[342785, 343076, 344399]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "a group of people on a raft in a river\n",
      "A group of people on a yellow and black raft next to trees.\n",
      "People on boats riding along a river with flowers on the bank.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  131101 \n",
      "\n",
      "image tensor shape:  torch.Size([640, 480, 3])\n",
      "Annotation IDs: \n",
      "[96872, 102482, 103844]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man in the rain holding an umbrella.\n",
      "A picture of a man in a white teeshirt with a heart umbrella.\n",
      "A man in a white shirt holding an opened pink umbrella\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  524317 \n",
      "\n",
      "image tensor shape:  torch.Size([640, 426, 3])\n",
      "Annotation IDs: \n",
      "[673671, 673887, 675468]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man in a cap dressed in clothing from a past era.\n",
      "A picture of a man with a hat and tie on.\n",
      "A man with an old-fashioned hat is looking at the camera.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  262175 \n",
      "\n",
      "image tensor shape:  torch.Size([410, 640, 3])\n",
      "Annotation IDs: \n",
      "[451462, 459391, 465262]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "a man is standing in the woods wearing a hat and glasses\n",
      "A man in sunglasses wears a grass tie and hat.\n",
      "A man wearing a woven crown and tie.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  524320 \n",
      "\n",
      "image tensor shape:  torch.Size([480, 640, 3])\n",
      "Annotation IDs: \n",
      "[599750, 600347, 601532]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A guy with a big coat and woman looking at him.\n",
      "a man and a woman are standing outside\n",
      "A man and a woman dressed in early times outfits.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  393251 \n",
      "\n",
      "image tensor shape:  torch.Size([500, 335, 3])\n",
      "Annotation IDs: \n",
      "[411621, 411891, 412299]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "There is a round cake and one adult and nod kid near it. \n",
      "A man slicing up a cake on top of a wooden table.\n",
      "A man cutting a cake with his child. \n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  131108 \n",
      "\n",
      "image tensor shape:  torch.Size([480, 640, 3])\n",
      "Annotation IDs: \n",
      "[695087, 697913, 699851]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "this is a street with a brick building\n",
      "a building with a sign and a street right outside\n",
      "Black and white image of an empty street. \n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  524325 \n",
      "\n",
      "image tensor shape:  torch.Size([423, 640, 3])\n",
      "Annotation IDs: \n",
      "[438177, 441540, 441774]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A group of people stand underneath bridge of kites.\n",
      "A group of young men flying kites on a beach with the town in the background.\n",
      "A crowd watches kites being flown in a demonstration.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  36 \n",
      "\n",
      "image tensor shape:  torch.Size([425, 640, 3])\n",
      "Annotation IDs: \n",
      "[552549, 556653, 556899]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "Woman in swim suit holding parasol on sunny day.\n",
      "A woman posing for the camera, holding a pink, open umbrella and wearing a bright, floral, ruched bathing suit, by a life guard stand with lake, green trees, and a blue sky with a few clouds behind.\n",
      "A woman in a floral swimsuit holds a pink umbrella.\n",
      "\n",
      "Type of anotations <class 'str'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image Id:  131115 \n",
      "\n",
      "image tensor shape:  torch.Size([333, 500, 3])\n",
      "Annotation IDs: \n",
      "[686267, 690140, 695090]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A baseball player holding a bat next to a base.\n",
      "A photo of a baseball game where a guy is at home plate taking a pitch.\n",
      "A baseball player attempts to hit a baseball, while a catcher and umpire watch.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  524333 \n",
      "\n",
      "image tensor shape:  torch.Size([427, 640, 3])\n",
      "Annotation IDs: \n",
      "[747766, 750678, 754276]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A group of people sitting around a table.\n",
      "this is a group of people eating a meal\n",
      "a group of people sitting around a big restaurant table \n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  262191 \n",
      "\n",
      "image tensor shape:  torch.Size([640, 426, 3])\n",
      "Annotation IDs: \n",
      "[355819, 358789, 359248]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A brown teddy bear sitting on top of a blue box.\n",
      "Someone placed that teddy bear at the bus stop.\n",
      "A teddy bear is sitting at a blue bus stop.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  49 \n",
      "\n",
      "image tensor shape:  torch.Size([640, 640, 3])\n",
      "Annotation IDs: \n",
      "[584400, 584589, 592140]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A couple of men riding horses on top of a green field.\n",
      "two horses and their riders on some grass\n",
      "Two men are on horses that are reared back.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  524338 \n",
      "\n",
      "image tensor shape:  torch.Size([480, 640, 3])\n",
      "Annotation IDs: \n",
      "[435921, 436695, 437382]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man is reading a newspaper on the side of the road\n",
      "Man standing beside a parking meter and tree in a city street. \n",
      "a man looking at a newspaper whiile standing next to a tree \n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  393267 \n",
      "\n",
      "image tensor shape:  torch.Size([380, 500, 3])\n",
      "Annotation IDs: \n",
      "[675203, 678521, 679571]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "Several people are standing at a table looking at wine bottles.\n",
      "A woman standing in front of a table surrounded by a crowd of people.\n",
      "A group of people at a table filled with wine bottles\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  393268 \n",
      "\n",
      "image tensor shape:  torch.Size([480, 640, 3])\n",
      "Annotation IDs: \n",
      "[59913, 60228, 62034]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man and woman play a video game while others watch.\n",
      "A group of people in a room looking at a tv.\n",
      "A man and a woman holding Nintendo Wii controllers.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  262197 \n",
      "\n",
      "image tensor shape:  torch.Size([426, 640, 3])\n",
      "Annotation IDs: \n",
      "[588719, 592823, 592862]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "a very tall brown structure sitting above a parking lot.\n",
      "A red brick school building with a student walking towards the building. \n",
      "A pair of buildings from a very far away view.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  393271 \n",
      "\n",
      "image tensor shape:  torch.Size([427, 640, 3])\n",
      "Annotation IDs: \n",
      "[795117, 795156, 796875]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "The image shows a series of a snowboarder's descent down the slope. \n",
      "A photograph of several images of the same young man ridding a snowboard through the woods.\n",
      "A time lapse image of a snowboarder gliding forward\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  262200 \n",
      "\n",
      "image tensor shape:  torch.Size([461, 640, 3])\n",
      "Annotation IDs: \n",
      "[284209, 286546, 287644]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A group of kids at table around a cake.\n",
      "A group of kids around a table with a cake.\n",
      "A group of kids watching a woman light a candle.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  131127 \n",
      "\n",
      "image tensor shape:  torch.Size([426, 640, 3])\n",
      "Annotation IDs: \n",
      "[303273, 303447, 303723]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man is filthy, holding bananas, while posing for the camera. \n",
      "A happy man holds up three bananas one of which is partially eaten.\n",
      "Hot and dirty man with bananas in each hand.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  61 \n",
      "\n",
      "image tensor shape:  torch.Size([480, 640, 3])\n",
      "Annotation IDs: \n",
      "[444409, 446671, 452062]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "They are brave for riding in the jungle on those elephants.\n",
      "SOME PEOPLE IN THE WOODS RIDING TWO ELEPHANTS\n",
      "Some people who are riding on top of elephants.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  262207 \n",
      "\n",
      "image tensor shape:  torch.Size([375, 500, 3])\n",
      "Annotation IDs: \n",
      "[755261, 756122, 759099]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man standing in front of a television near a large window.\n",
      "a man standing by a tv in the corner of the room \n",
      "A man standing very close to a television in a living room.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  393284 \n",
      "\n",
      "image tensor shape:  torch.Size([426, 640, 3])\n",
      "Annotation IDs: \n",
      "[164707, 186142, 192058]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A snowboarder crouching on his board in mid air.\n",
      "A snowboarder and his board caught mid flight\n",
      "A man flying through the air while riding a snowboard.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  74 \n",
      "\n",
      "image tensor shape:  torch.Size([640, 480, 3])\n",
      "Annotation IDs: \n",
      "[145996, 146710, 149398]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A picture of a dog laying on the ground.\n",
      "Dog snoozing by a bike on the edge of a cobblestone street\n",
      "The white dog lays next to the bicycle on the sidewalk.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  393290 \n",
      "\n",
      "image tensor shape:  torch.Size([359, 640, 3])\n",
      "Annotation IDs: \n",
      "[520515, 520953, 523338]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A woman holding a white plate with a pizza on it.\n",
      "A woman holding a pizza on a tray in a restaurant.\n",
      "A woman carrying a pizza on a plate \n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  262221 \n",
      "\n",
      "image tensor shape:  torch.Size([640, 426, 3])\n",
      "Annotation IDs: \n",
      "[674703, 675942, 684285]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A tennis player is walking while holding his racket\n",
      "Player and referee at tennis match on red court.\n",
      "A man sitting on a high chair on a tennis court.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  524366 \n",
      "\n",
      "image tensor shape:  torch.Size([427, 640, 3])\n",
      "Annotation IDs: \n",
      "[146804, 146996, 150236]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "Motion blur photograph of a motorcyclist on the freeway\n",
      "A person riding their motorcycle on a road.\n",
      "A man on a motorcycle is driving down the street.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  77 \n",
      "\n",
      "image tensor shape:  torch.Size([427, 640, 3])\n",
      "Annotation IDs: \n",
      "[567271, 569752, 573184]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A young man riding a skateboard into the air.\n",
      "a group of teenagers jumping a ramp on their skateboards\n",
      "A time lapse image of a guy on a skate board.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  131152 \n",
      "\n",
      "image tensor shape:  torch.Size([640, 426, 3])\n",
      "Annotation IDs: \n",
      "[736226, 740972, 741749]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "a man riding a surfboard close to the shore \n",
      "A surfer riding a wave onto the beach with multiple surfers behind him.\n",
      "A man riding a wave on top of a surfboard.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  524373 \n",
      "\n",
      "image tensor shape:  torch.Size([418, 640, 3])\n",
      "Annotation IDs: \n",
      "[568025, 574676, 575345]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A giraffe standing next to a palm tree on a field.\n",
      "Two giraffes and a zebra roam in a preserve area\n",
      "One large giraffe in the foreground with another and a zebra in the background\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  262229 \n",
      "\n",
      "image tensor shape:  torch.Size([500, 375, 3])\n",
      "Annotation IDs: \n",
      "[623154, 626718, 626793]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A group of young ladies playing a game of soccer.\n",
      "Four girls are playing soccer in the field. \n",
      "A few women on a field playing soccer\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  86 \n",
      "\n",
      "image tensor shape:  torch.Size([425, 640, 3])\n",
      "Annotation IDs: \n",
      "[50422, 51673, 58675]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man riding a motor bike across a forest.\n",
      "A man sitting on a motorcycle in the woods.\n",
      "A young person is on a very ornate old bicycle.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  524375 \n",
      "\n",
      "image tensor shape:  torch.Size([612, 612, 3])\n",
      "Annotation IDs: \n",
      "[3395, 6947, 9497]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man watches a bunch of cattle graze in the field.\n",
      "Sheep and goats grazing in the pasture with a person looking over them.\n",
      "Goats grazing on a grassy hillside being watched over by a herder.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  393306 \n",
      "\n",
      "image tensor shape:  torch.Size([427, 640, 3])\n",
      "Annotation IDs: \n",
      "[149930, 185378, 197927]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man sitting on top of a couch next to wilted flowers.\n",
      "Man sitting on covered furniture behind vase of dying flowers\n",
      "A man reclines on a chair with dead flowers in the foreground. \n",
      "\n",
      "Type of anotations <class 'str'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image Id:  262235 \n",
      "\n",
      "image tensor shape:  torch.Size([450, 640, 3])\n",
      "Annotation IDs: \n",
      "[604030, 605374, 605638]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A beautiful young lady talking on a phone while smiling.\n",
      "A woman with a lanyard and name tag while on a cell phone.\n",
      "A woman standing in a corner by a curtain taking a cell phone call. \n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  262238 \n",
      "\n",
      "image tensor shape:  torch.Size([640, 457, 3])\n",
      "Annotation IDs: \n",
      "[794748, 795627, 796548]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A man wearing knee pads is riding a skateboard.\n",
      "The person wearing knee pads is balancing on a skateboard. \n",
      "A person is performing a trick on a skateboard.\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  262239 \n",
      "\n",
      "image tensor shape:  torch.Size([428, 640, 3])\n",
      "Annotation IDs: \n",
      "[738501, 738654, 740823]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "a couple of people are cooking in a room\n",
      "Two people in chef's outfits cooking inside a kitchen. \n",
      "two chefs working on seperate parts of a meal at a restaurant\n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  262242 \n",
      "\n",
      "image tensor shape:  torch.Size([500, 333, 3])\n",
      "Annotation IDs: \n",
      "[549896, 556412, 556508]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A woman standing on a tennis court holding a racquet.\n",
      "A woman picking up a ball with a tennis racquet.\n",
      "Three people with racquets stand on a tennis court. \n",
      "\n",
      "Type of anotations <class 'str'>\n",
      "\n",
      "\n",
      "Image Id:  131172 \n",
      "\n",
      "image tensor shape:  torch.Size([428, 640, 3])\n",
      "Annotation IDs: \n",
      "[805685, 807278, 808295]\n",
      "\n",
      " 3 top selected Annotations: \n",
      "A group of people are sitting on a bench outside.\n",
      "A man sitting by a woman and girl who are on their cell phones.\n",
      "A black and white photograph of people on a bench table.\n",
      "\n",
      "Type of anotations <class 'str'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-86048daabf31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadImgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgId\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadImgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgIds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgIds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coco_url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#'C:/Users/pasan/Documents/Motivation/cocoapi-master/PythonAPI/train2017/'+img['file_name']\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\nImage Id: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skimage\\io\\_io.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, as_grey, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mplugin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'tifffile'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imread'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skimage\\io\\util.py\u001b[0m in \u001b[0;36mfile_or_url_context\u001b[1;34m(resource_name)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNamedTemporaryFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[1;31m# f must be closed before yielding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m                     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load and display caption annotations\n",
    "catIds = coco.getCatIds(catNms=['person']);\n",
    "imgIds = coco.getImgIds(catIds=catIds );\n",
    "print('No. of images, category : people - ', len(imgIds))\n",
    "j = 0\n",
    "for imgId in imgIds:\n",
    "    fann = []\n",
    "    i = 0\n",
    "    img = coco.loadImgs(imgId)\n",
    "    img = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\n",
    "    I = io.imread(img['coco_url'])#'C:/Users/pasan/Documents/Motivation/cocoapi-master/PythonAPI/train2017/'+img['file_name']\n",
    "    K = torch.from_numpy(I)\n",
    "    print('\\n\\nImage Id: ', imgId, '\\n')\n",
    "    print( 'image tensor shape: ', K.shape)\n",
    "    annIds = coco_caps.getAnnIds(imgId)\n",
    "    \n",
    "    for annId in annIds :\n",
    "        if(i< 3):\n",
    "            fann.append(annId) \n",
    "            i = i+1\n",
    "    print('Annotation IDs: ')        \n",
    "    print(fann)\n",
    "    anns = coco_caps.loadAnns(fann)\n",
    "    print('\\n 3 top selected Annotations: ')\n",
    "    anns = coco_caps.showAnns(anns)\n",
    "    anns = str(anns)\n",
    "    print('\\nType of anotations', type(anns))\n",
    "\n",
    "# annIds = coco_caps.getAnnIds(imgIds=img['id']);\n",
    "# anns = coco_caps.loadAnns(annIds)\n",
    "# coco_caps.showAnns(anns)\n",
    "# plt.imshow(I); plt.axis('off'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
